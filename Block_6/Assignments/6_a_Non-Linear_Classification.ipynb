{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 1: Non-Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "We return to the MNIST data set on handwritten digits to compare non-linear classification algorithms ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the full MNIST data set contains 70k samples of digits 0-9 as 28*28 gray scale images (represented as 784 dim vectors)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at max/min value in the data\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.1: Cross-Validation and Support Vector Machines\n",
    "Train and optimize  C-SVM classifier on MNIST (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "* use a RBF kernel\n",
    "* use *random search* with cross-validation to find the best settings for *gamma* and *C* (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#welche Parameter gibt es\n",
    "SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma\n",
    "param = {'C':[1, 10, 100, 1000], \n",
    "          'cache_size':[200], \n",
    "          'gamma': [0.01, 0.001, 0.0001], \n",
    "          'kernel':['rbf']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                 class_weight=None, coef0=0.0,\n",
       "                                 decision_function_shape='ovr', degree=3,\n",
       "                                 gamma='scale', kernel='rbf', max_iter=20,\n",
       "                                 probability=False, random_state=None,\n",
       "                                 shrinking=True, tol=0.001, verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'C': [1, 10, 100, 1000],\n",
       "                                        'cache_size': [200],\n",
       "                                        'gamma': [0.01, 0.001, 0.0001],\n",
       "                                        'kernel': ['rbf']},\n",
       "                   pre_dispatch='n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svc_model = SVC(max_iter=20)\n",
    "randm_search = RandomizedSearchCV(svc_model, param, cv=3, n_jobs=-1, pre_dispatch='n_jobs')\n",
    "\n",
    "randm_search.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 0.0001, 'cache_size': 200, 'C': 1}\n",
      "0.7045575262004656\n"
     ]
    }
   ],
   "source": [
    "print(randm_search.best_params_)\n",
    "print(randm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Modell trainieren\n",
    "#beste gamma wert laut schritt vorher: 0,0001\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SVC_with_best = SVC(gamma=0.0001, max_iter=50)\n",
    "scaled_best = make_pipeline(StandardScaler(), SVC_with_best)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaled_best.fit(X_train, y_train)\n",
    "\n",
    "predicted = scaled_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9' '9' '4' ... '0' '9' '8']\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('svc',\n",
      "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
      "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
      "                     gamma=0.0001, kernel='rbf', max_iter=50, probability=False,\n",
      "                     random_state=None, shrinking=True, tol=0.001,\n",
      "                     verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "print(scaled_best.fit(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.2: Pipelines and simple Neural Networks\n",
    "Split the MNIST data into  train- and test-sets and then train and evaluate a simple Multi Layer Perceptron (MLP) network. Since the non-linear activation functions of MLPs are sensitive to the scaling on the input (recall the *sigmoid* function), we need to scale all input values to [0,1] \n",
    "\n",
    "* combine all steps of your training in a SKL pipeline (https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "* use a SKL-scaler to scale the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* MLP Parameters: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "    * use a *SGD* solver\n",
    "    * use *tanh* as activation function\n",
    "    * compare networks with 1, 2 and 3 layers, use different numbers of neurons per layer\n",
    "    * adjust training parameters *alpha* (regularization) and *learning rate* - how sensitive is the model to these parameters?\n",
    "    * Hint: do not change all parameters at the same time, split into several experiments\n",
    "* How hard is it to find the best parameters? How many experiments would you need to find the best parameters?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runde 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(28,28), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(28,28), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.01, \n",
    "                                         max_iter=50))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(28,28,28, 28), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.001, \n",
    "                                         max_iter=300))\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1]\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(64,64), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.0001, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15688793 0.84311207]\n",
      " [0.97981397 0.02018603]\n",
      " [0.05585516 0.94414484]\n",
      " [0.31830517 0.68169483]\n",
      " [0.04259432 0.95740568]\n",
      " [0.94194757 0.05805243]\n",
      " [0.93741591 0.06258409]\n",
      " [0.08513987 0.91486013]\n",
      " [0.61300887 0.38699113]\n",
      " [0.96846751 0.03153249]\n",
      " [0.98503895 0.01496105]\n",
      " [0.06646362 0.93353638]\n",
      " [0.12536707 0.87463293]\n",
      " [0.91985209 0.08014791]\n",
      " [0.16789189 0.83210811]\n",
      " [0.91064496 0.08935504]\n",
      " [0.89067313 0.10932687]\n",
      " [0.86701097 0.13298903]\n",
      " [0.97761815 0.02238185]\n",
      " [0.44688805 0.55311195]\n",
      " [0.05457322 0.94542678]\n",
      " [0.08683231 0.91316769]\n",
      " [0.93596826 0.06403174]\n",
      " [0.90712652 0.09287348]\n",
      " [0.19409603 0.80590397]]\n",
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1]\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(64,64), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.000001, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runde 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(60,56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(64,56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1]\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(1,56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(2,56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1]\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aline\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "model_pipe = make_pipeline(StandardScaler(), \n",
    "                           MLPClassifier(random_state=1, \n",
    "                                         activation='tanh',\n",
    "                                         hidden_layer_sizes=(3,56), \n",
    "                                         solver='sgd', \n",
    "                                         alpha=0.1, \n",
    "                                         max_iter=300))\n",
    "\n",
    "model_pipe.fit(X_train, y_train)\n",
    "\n",
    "#print(model_pipe.predict_proba(X_test))\n",
    "\n",
    "print(model_pipe.predict(X_test))\n",
    "\n",
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
