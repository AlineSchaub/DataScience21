{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 2: finding the best parameters for predicting the fare of taxi rides\n",
    "We return to our Random Forest Regression and want to automatically optimize all free parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data we have saved after wrangling and pre-processing in block I\n",
    "X=pd.read_csv('../../DATA/train_cleaned.csv')\n",
    "drop_columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','key','pickup_datetime','pickup_date','pickup_latitude_round3','pickup_longitude_round3','dropoff_latitude_round3','dropoff_longitude_round3']\n",
    "X=X.drop(drop_columns,axis=1)\n",
    "X=pd.get_dummies(X)# one hot coding\n",
    "#generate labels\n",
    "y=X['fare_amount']\n",
    "X=X.drop(['fare_amount'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Optimize\n",
    "Scikit Optimize (https://scikit-optimize.github.io/stable/index.html) is a AutoML toolbox wrapped around Scikit-Learn. It allows us to use state-of-the-art automatic hyper-parameter optimization on top of our learning algorithms.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\aline\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\aline\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.3)\n"
     ]
    }
   ],
   "source": [
    "# install \n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E 2.1 Bayesian Optimization of a Random Forest Regression Model\n",
    "use Bayesian Optimization with Cross-Validation (https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV) to find the best regression model. Compare\n",
    "* linear regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) \n",
    "* Random Forest regression (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "* and SVM regression (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)\n",
    "\n",
    "NOTES: this can become quite compute intensive! Hence,\n",
    "* use a smaller subset of the training data to run the experiments \n",
    "* think about the range of your parameters (e.g. larger number of trees in RF or high C-values in SMV will make models expensive)\n",
    "* optimize only the following parameters per model type:\n",
    "    * linear: no parameters to optimize\n",
    "    * RF: #trees and depth\n",
    "    * SVM: C and gamma (use RBF kernel)\n",
    "* parallelize -> n_jobs\n",
    "* use CoLab to rum the job for up to 12h \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "#test mit 5000 Trainingsdaten\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy()[:50,:], y.to_numpy()[:50], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "37\n",
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687207464656822\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_opt = BayesSearchCV( \n",
    "         RandomForestRegressor(),\n",
    "         {\n",
    "             'n_estimators':[10,20,50],\n",
    "             'max_depth':[2, 4, 6, 8, 10]\n",
    "         },\n",
    "         n_iter=32,\n",
    "         random_state=0,\n",
    "         n_jobs=-1,\n",
    "         cv=3,\n",
    "         #scoring='neg_mean_squared_error'\n",
    "     )\n",
    "\n",
    "random_optimal = random_opt.fit(X_train, y_train)\n",
    "print(random_opt.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('max_depth', 8), ('n_estimators', 20)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_optimal.best_score_\n",
    "random_optimal.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(random_optimal.cv_results_)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05946067724581483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "svr_opt = BayesSearchCV(\n",
    "    SVR(),\n",
    "    {\n",
    "        'C': [0.1, 0.2, 0.3, 0.5, 1.0],\n",
    "        'gamma': [0.1, 0.01, 0.001, 0.0001, 1.0],\n",
    "        'kernel': ['rbf'],\n",
    "    },\n",
    "    n_iter=32,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch='n_jobs'\n",
    ")\n",
    "\n",
    "\n",
    "svr_optimal = svr_opt.fit(X_train, y_train)\n",
    "print(svr_opt.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('C', 0.5), ('gamma', 0.001), ('kernel', 'rbf')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_optimal.best_score_\n",
    "svr_optimal.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_svr = pd.DataFrame(svr_optimal.cv_results_)\n",
    "#print(df_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The search_spaces parameter should contain at least onenon-empty search space, got {}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-f0feefc93d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n_jobs'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, estimator, search_spaces, optimizer_kwargs, n_iter, scoring, fit_params, n_jobs, n_points, iid, refit, cv, verbose, pre_dispatch, random_state, error_score, return_train_score)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_search_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_spaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m         \u001b[1;31m# Temporary fix for compatibility with sklearn 0.20 and 0.21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# See scikit-optimize#762\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_check_search_space\u001b[1;34m(self, search_space)\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n\u001b[0;32m    320\u001b[0m                 \u001b[1;34m\"The search_spaces parameter should contain at least one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                 \u001b[1;34m\"non-empty search space, got %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The search_spaces parameter should contain at least onenon-empty search space, got {}"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_opt = BayesSearchCV(\n",
    "    LinearRegression(),\n",
    "    {\n",
    "        {'C': range(1,20)}\n",
    "    },\n",
    "    \n",
    "    n_iter=32,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch='n_jobs'\n",
    ")\n",
    "\n",
    "#lin_opt.get_params().keys()\n",
    "\n",
    "lin_optimal = lin_opt.fit(X_train, y_train)\n",
    "print(lin_opt.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_optimal.best_score_\n",
    "lin_optimal.best_params_\n",
    "lin_optimal.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear = pd.DataFrame(df_linear.cv_results_)\n",
    "print(df_linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
